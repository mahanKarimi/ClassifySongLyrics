{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "# load dataset \n",
    "pathLyrics = 'lyrics-data.csv'\n",
    "pathArtists = 'artists-data.csv'\n",
    "\n",
    "\n",
    "dataframe = pd.read_csv(pathLyrics)\n",
    "dataframeArtists = pd.read_csv(pathArtists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter Idiom for olny english lyrics\n",
    "dataframe = dataframe[dataframe['Idiom'] == 'ENGLISH']\n",
    "\n",
    "# normalize lycris to lowercase  \n",
    "dataframe['Lyric'] = dataframe['Lyric'].apply(lambda lyric: lyric.lower())\n",
    "\n",
    "# Zwei csv werden gemerged\n",
    "mergeData=pd.merge(dataframe, dataframeArtists, how='inner', left_on='ALink', right_on='Link')\n",
    "\n",
    "#Filtern der Daten. Nur Lyric und Genre für das Dataset notwendig\n",
    "rawData= mergeData[['Lyric', 'Genre']]\n",
    "\n",
    "# Es werden die Spalten gefiltert, die Noten enthalten\n",
    "rawData = rawData[~rawData['Lyric'].str.contains('----')] \n",
    "\n",
    "#Filtert alle Zeichen bis auf Buchstaben und Zahlen heraus\n",
    "rawData['Lyric']=rawData['Lyric'].str.replace('[^a-zA-Z0-9]', ' ')\n",
    "rawData = rawData.drop_duplicates(subset='Lyric')\n",
    "#train, test = train_test_split(rawData, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "dataframe = dataframe[dataframe['Idiom'] == 'ENGLISH']\n",
    "dataframe['Lyric'] = dataframe['Lyric'].apply(lambda lyric: lyric.lower())\n",
    "\n",
    "patternDel = [\"---\", \"instrumental\",\"===\"]\n",
    "for patt in patternDel:\n",
    "    filter = dataframe['Lyric'].str.contains(patt)\n",
    "    dataframe = dataframe[~filter]\n",
    "\n",
    "\n",
    "mergeData=pd.merge(dataframe, dataframeArtists, how='inner', left_on='ALink', right_on='Link')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#mergeData.to_csv('merge.csv')\n",
    "#rawData = shuffle(mergeData)\n",
    "rawData= mergeData[['Lyric', 'Genre', 'Genres']]\n",
    "rawData = rawData.drop_duplicates(subset='Lyric')\n",
    "\n",
    "\n",
    "#rawData.dropna(axis=0, how='any',thresh=None, subset=None,inplace=True)\n",
    "rawData.to_csv('rawData.csv')\n",
    "\n",
    "#rawData.to_csv('merge.csv')\n",
    "train, test = train_test_split(rawData, test_size=0.2)\n",
    "\n",
    "\n",
    "#pathLyrics = 'lyrics-data.csv'\n",
    "#test = pd.read_csv('test.csv', sep=';')\n",
    "#rawData= test[['Lyric', 'Genre']]\n",
    "#rawData = shuffle(rawData)\n",
    "#train, test = train_test_split(rawData, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_cnt = vectorizer.fit_transform(rawData['Lyric'])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_clean = label_encoder.fit_transform(rawData['Genre'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cnt, y_clean, test_size=0.2, random_state=0)\n",
    "\n",
    "## Naive Bayes mit additiver Glättung trainieren\n",
    "nb = MultinomialNB(alpha=1.0)\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "## Vorhersagen berechnen\n",
    "y_predicted = nb.predict(X_test)\n",
    "\n",
    "\n",
    "## Konfusionsmatrix ausgeben\n",
    "print(\"Kofusionsmatrix:\\n\", confusion_matrix(y_true=y_test, y_pred=y_predicted))\n",
    "\n",
    "## Gütemaße ausgeben\n",
    "print(\"Korrektklassifizierungsrate:\\n\", accuracy_score(y_true=y_test, y_pred=y_predicted))\n",
    "print(\"Präzision (mikro):\\n\", precision_score(y_true=y_test, y_pred=y_predicted, average='micro'))\n",
    "print(\"Ausbeute (mikro):\\n\", recall_score(y_true=y_test, y_pred=y_predicted, average='micro'))\n",
    "print(\"F1 (mikro):\\n\", f1_score(y_true=y_test, y_pred=y_predicted, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequences (dataframe, dimensions=10000):\n",
    "    vect = CountVectorizer()\n",
    "    X = vect.fit_transform(dataframe)\n",
    "    tokenizer = Tokenizer(num_words=dimensions)\n",
    "    tokenizer.fit_on_texts(dataframe)\n",
    "    sequences = tokenizer.texts_to_sequences(dataframe)\n",
    "    one_hot_results = tokenizer.texts_to_matrix(dataframe, mode='binary')\n",
    "    word_index = tokenizer.word_index\n",
    "    print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "    return one_hot_results\n",
    "    \n",
    "def vectorize_labels(labels):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    encodedlabels = le.fit(labels)\n",
    "    encodedlabels_transformed= le.transform(labels) \n",
    "    return to_categorical(encodedlabels_transformed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Feed Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorize_sequences(train['Lyric'])\n",
    "#y_train = vectorize_sequences(train['Genre'], 6)\n",
    "y_train = vectorize_labels(train['Genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(128, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(6, activation='softmax'))\n",
    "#model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=50,batch_size=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "train_loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "plt.title('Training and validation loss')\n",
    "plt.plot(epochs, train_loss, label='Training loss')\n",
    "plt.plot(epochs, val_loss, label='Validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorize_sequences(test['Lyric'])\n",
    "Y_test = vectorize_labels(test['Genre']) \n",
    "\n",
    "\n",
    "# compute loss and accuracy on test data\n",
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(\"Test score:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "train_acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.plot(epochs, train_acc, label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, label='Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced FFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#tfidf_vectorizer=TfidfVectorizer(stop_words=\"english\", use_idf=True, max_features=10000)\n",
    "tfidf_vectorizer=TfidfVectorizer(use_idf=True, max_features=10000) \n",
    "# just send in all your docs here\n",
    "xtrain_tfidf = tfidf_vectorizer.fit(train['Lyric'])\n",
    "\n",
    "X_train = xtrain_tfidf.transform(train['Lyric'])\n",
    "y_train = vectorize_labels(train['Genre'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tfidf = models.Sequential()\n",
    "model_tfidf.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model_tfidf.add(layers.Dense(16, activation='relu'))\n",
    "model_tfidf.add(layers.Dense(6, activation='softmax'))\n",
    "model_tfidf.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#model_tfidf.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_tfidf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history_tfidf = model_tfidf.fit(X_train, y_train, epochs=50, batch_size=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history_tfidf.history\n",
    "train_loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "plt.title('Training and validation loss')\n",
    "plt.plot(epochs, train_loss, label='Training loss')\n",
    "plt.plot(epochs, val_loss, label='Validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest_tfidf = tfidf_vectorizer.fit(test['Lyric'])\n",
    "\n",
    "X_test = xtest_tfidf.transform(test['Lyric'])\n",
    "\n",
    "\n",
    "Y_test = vectorize_labels(test['Genre'])\n",
    "\n",
    "# compute loss and accuracy on test data\n",
    "score = model_tfidf.evaluate(X_test, Y_test, verbose=1)\n",
    "print(\"Test score:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history_tfidf.history\n",
    "train_acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.plot(epochs, train_acc, label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, label='Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
